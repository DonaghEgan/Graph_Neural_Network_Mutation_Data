{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import read_folders as rf\n",
    "import numpy as np\n",
    "import utility_functions as uf\n",
    "import random\n",
    "import read_specific as rs\n",
    "import torch\n",
    "import cox_loss as cl\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, IterableDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from torch_geometric.nn import GraphConv, global_add_pool\n",
    "from torch.nn import Linear\n",
    "from torch import optim\n",
    "from cox_loss import cox_loss_effron\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import download_study as ds\n",
    "from torch_geometric.data import Data, Batch\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using existing file tmb_mskcc_2018.tar.gz\n",
      "Extracting temp/tmb_mskcc_2018.tar.gz\n",
      "Extracting temp/tmb_mskcc_2018.tar.gz\n"
     ]
    }
   ],
   "source": [
    "path, sources, urls = ds.download_study(name = 'msk_immuno_2019')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Samples not in mutation data\n",
      "Genes missing from length dict: []\n",
      "0 Samples not in SV data\n"
     ]
    }
   ],
   "source": [
    "data_dict = rf.read_files(path[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_muts shape: Not a NumPy array, type is int64\n",
      "patient_array shape: (1661, 4)\n",
      "os_array shape: (1661, 2)\n",
      "mutations.mut_pos shape: (1661, 554, 12)\n",
      "mutations.var_type shape: (1661, 554, 5, 12)\n",
      "mutations.aa_sub shape: (1661, 554, 48, 12)\n",
      "mutations.ns shape: (1661, 554, 12)\n",
      "sv.chrom shape: (1661, 554, 46, 12)\n",
      "sv.var_class shape: (1661, 554, 6, 12)\n"
     ]
    }
   ],
   "source": [
    "def print_shapes(data, prefix=\"\"):\n",
    "    for key, value in data.items():\n",
    "        full_key = f\"{prefix}.{key}\" if prefix else key\n",
    "        if isinstance(value, list):\n",
    "            continue\n",
    "        if isinstance(value, dict):\n",
    "            print_shapes(value, prefix=full_key)  # recursive call\n",
    "        elif isinstance(value, np.ndarray):\n",
    "            print(f\"{full_key} shape: {value.shape}\")\n",
    "        else:\n",
    "            print(f\"{full_key} shape: Not a NumPy array, type is {type(value).__name__}\")\n",
    "\n",
    "print_shapes(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mut_pos = data_dict['mutations']['mut_pos']      # Shape (1661, 554, 12) -> Needs reshape\n",
    "var_type = data_dict['mutations']['var_type']   # Shape (1661, 554, 5, 12)\n",
    "aa_sub = data_dict['mutations']['aa_sub']      # Shape (1661, 554, 48, 12) 24 aa (ref and alt)\n",
    "ns = data_dict['mutations']['ns']              # Shape (1661, 554, 12) -> Needs reshape\n",
    "chrom = data_dict['sv']['chrom']              # Shape (1661, 554, 46, 12)  46 = 23 * 2 (ref and alt chromosome)\n",
    "var_class = data_dict['sv']['var_class']       # Shape (1661, 554, 6, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_last_two_dims(x):\n",
    "    # x.shape == (1661, 554, D, 12)\n",
    "    n0, n1, D, C = x.shape\n",
    "    return x.reshape(n0, n1, D*C)\n",
    "\n",
    "aa_sub_flat    = merge_last_two_dims(aa_sub)     # → (1661, 554, 48*12  = 576)\n",
    "chrom_flat     = merge_last_two_dims(chrom)      # → (1661, 554, 46*12  = 552)\n",
    "var_class_flat = merge_last_two_dims(var_class)  # → (1661, 554,  6*12  =  72)\n",
    "var_type_flat = merge_last_two_dims(var_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1661, 554, 552)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chrom_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_data = data_dict['patient_array']\n",
    "gene_list = data_dict['gene_list']\n",
    "osurv_data = data_dict['os_array']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a list of arrays in the desired concatenation order\n",
    "arrays_to_concat = [\n",
    "    mut_pos,  # Size 1 along axis 2\n",
    "    var_type_flat,    # Size 5 along axis 2\n",
    "    aa_sub_flat,      # Size 48 along axis 2\n",
    "    ns,       # Size 1 along axis 2\n",
    "    chrom_flat,       # Size 46 along axis 2\n",
    "    var_class_flat    # Size 6 along axis 2\n",
    "]\n",
    "omics = np.concatenate(arrays_to_concat, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1661, 554, 1284)\n"
     ]
    }
   ],
   "source": [
    "print(omics.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "554\n"
     ]
    }
   ],
   "source": [
    "genes_to_keep_mask = np.any(omics != 0, axis=(0, 2))\n",
    "print(len(genes_to_keep_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will set a seed and split into training (80%), validation (10%) and testing (10%)\n",
    "sample_list = data_dict['sample_list'] # get samples\n",
    "random.seed(3)\n",
    "sample_index = [i for i in range(len(sample_list))]\n",
    "random.shuffle(sample_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrain = int(0.8*len(sample_list))\n",
    "nval = int(0.1*len(sample_list))\n",
    "\n",
    "train_set = sample_index[0:ntrain]\n",
    "val_set = sample_index[ntrain:(ntrain+nval)]\n",
    "test_set = sample_index[(ntrain+nval):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "omics_train = omics[train_set]\n",
    "omics_test = omics[test_set]\n",
    "omics_val = omics[val_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "clin_train = clinical_data[train_set] \n",
    "clin_test = clinical_data[test_set]\n",
    "clin_val = clinical_data[val_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "osurv_train = osurv_data[train_set]\n",
    "osurv_test = osurv_data[test_set]\n",
    "osurv_val = osurv_data[val_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using existing file FIsInGene_122921_with_annotations.txt.zip\n",
      "Extracting temp/FIsInGene_122921_with_annotations.txt.zip\n"
     ]
    }
   ],
   "source": [
    "# Get the graph with the data. \n",
    "graph = rs.read_reactome(gene_list)\n",
    "tokens = torch.tensor(np.arange(0,len(gene_list)))\n",
    "\n",
    "edges_all = graph['edges_index_grn_act'] + graph['edges_index_grn_rep'] + graph['edges_index_ppi_act'] + graph['edges_index_ppi_inh'] + graph['edges_index_ppi_bin']\n",
    "edges_index_torch = torch.tensor(edges_all)\n",
    "edges_index_torch =  edges_index_torch.transpose(1,0)\n",
    "tokens = torch.tensor(np.arange(0,len(gene_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gin_omics(nn.Module):\n",
    "\n",
    "    def __init__(self, feats_in, feats_out, edge_index, max_tokens):\n",
    "        super(gin_omics, self).__init__()\n",
    "        \"\"\"\n",
    "        feats_in: Number of gene-level input features\n",
    "        feats_out: Number of output features per gene\n",
    "        edge_index: (2, num_edges) tensor defining gene-gene interactions\n",
    "        max_tokens: Total number of genes\n",
    "        \"\"\"\n",
    "        # Build adjacency matrix for gene aggregation\n",
    "        self.adj = torch.zeros((max_tokens, max_tokens), dtype=torch.float)\n",
    "        self.adj[edge_index[0], edge_index[1]] = 1.0\n",
    "        self.adj.fill_diagonal_(1.0) # maintain self loop\n",
    "            \n",
    "        self.lin_1 = Linear(feats_in, feats_out, bias=False)\n",
    "        self.lin_2 = Linear(feats_out, feats_out, bias=False)\n",
    "        self.gene_weights = nn.Parameter(torch.randn(max_tokens, feats_in))\n",
    "        self.act1 = nn.LeakyReLU()\n",
    "        self.act2 = nn.LeakyReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, G, F)\n",
    "\n",
    "        # 1) per-gene, per-feature-type weights of shape (G, F):\n",
    "        w = self.gene_weights            \n",
    "        w = w.unsqueeze(0)  # (1, G, F)\n",
    "            \n",
    "        # 2) apply weights to each occurrence:\n",
    "        x = x * w  # stays (1, G, F)                     \n",
    "\n",
    "        x2 = torch.matmul(x.transpose(1, 2), self.adj)  # dot product\n",
    "        x = x + x2.transpose(1, 2)                     \n",
    "\n",
    "        x = self.lin_1(x)     \n",
    "        x = self.act1(x)\n",
    "        x = self.lin_2(x)\n",
    "        x = self.act2(x)\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_omics(torch.nn.Module):\n",
    "    def __init__(self, features_omics, features_clin, dim, max_tokens, edge_index, output = 21):\n",
    "        super(Net_omics, self).__init__()\n",
    "        self.gin1 = gin_omics(features_omics, dim, edge_index, max_tokens)\n",
    "        self.gin2 = gin_omics(dim, dim, edge_index, max_tokens)\n",
    "        self.gin3 = gin_omics(dim, 1, edge_index, max_tokens)\n",
    "        self.linout = Linear(max_tokens, output, bias = False)\n",
    "        self.max_tokens = max_tokens\n",
    "        self.features_omics = features_omics\n",
    "        self.tokens = torch.tensor(np.arange(0,max_tokens))\n",
    "        self.linclin = Linear(features_clin, 1)\n",
    "        self.lin3 = Linear(output, 5)\n",
    "        \n",
    "    def forward(self, omics, clin):\n",
    "        # get the weights for the connections through kd.\n",
    "        x = self.gin1(omics)\n",
    "        x = self.gin2(x)\n",
    "        x = self.gin3(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.linout(x)\n",
    "        x2 = self.linclin(clin)\n",
    "        x1 = self.lin3(x) + x2\n",
    "        return x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net_omics(features_omics=omics_train.shape[2], features_clin=clin_train.shape[-1], dim=50, max_tokens=len(gene_list), edge_index=edges_index_torch, output=2).to(device)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can make a training function!\n",
    "def train_block(model, data):\n",
    "    model.train()\n",
    "    loss_all = 0\n",
    "    c_index = 0\n",
    "    j = 0\n",
    "    for batch in data:\n",
    "\n",
    "        batch = uf.move_batch_to_device(batch=batch, device=device) # wrapper for moving batch to gpu\n",
    "        j += 1\n",
    "\n",
    "        # set the gradients in the optimizer to zero.\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # run the model\n",
    "        pred = model(batch.omics, batch.clin)\n",
    "        \n",
    "        # calculate Cox' partial likelihood and get the autograd output.\n",
    "        loss = cox_loss_effron(batch.osurv, pred)\n",
    "        loss.backward()\n",
    "        \n",
    "        # update the loss_all object\n",
    "        loss_all += loss.item()\n",
    "        \n",
    "        # update parameters in model.\n",
    "        optimizer.step()\n",
    "        \n",
    "        # calculate concordance index\n",
    "        c_index += cl.concordance_index(batch.osurv, pred)\n",
    "\n",
    "    return loss_all/j, c_index/j\n",
    "\n",
    "# We will make a testing function too. \n",
    "def evaluate_model(model, data):\n",
    "    \"\"\"\n",
    "    Evaluate the model on a validation or test set.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The trained model.\n",
    "        loader (DataLoader): DataLoader for validation or test data.\n",
    "\n",
    "    Returns:\n",
    "        Tuple (avg_loss, avg_c_index): Mean Cox loss and concordance index over batches.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    loss_all = 0\n",
    "    c_index = 0\n",
    "    num_batches = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data:\n",
    "            batch = uf.move_batch_to_device(batch, device=device)\n",
    "            num_batches += 1\n",
    "            pred = model(batch.omics, batch.clin)\n",
    "            loss = cox_loss_effron(batch.osurv, pred)\n",
    "            loss_all += loss.item()\n",
    "            c_index += cl.concordance_index(batch.osurv, pred)\n",
    "\n",
    "    return loss_all / num_batches, c_index / num_batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoxBatchDataset(IterableDataset):\n",
    "    def __init__(self, osurv, clin, omics, batch_size=10, shuffle=True):\n",
    "        # Convert to tensors if needed\n",
    "        self.osurv = osurv if isinstance(osurv, torch.Tensor) else torch.tensor(osurv, dtype=torch.float)\n",
    "        self.clin = clin if isinstance(clin, torch.Tensor) else torch.tensor(clin, dtype=torch.float)\n",
    "        self.omics = omics if isinstance(omics, torch.Tensor) else torch.tensor(omics, dtype=torch.float)\n",
    "\n",
    "        if self.osurv.shape[0] < batch_size:\n",
    "            raise ValueError(\"Dataset size smaller than batch size\")\n",
    "\n",
    "        self.deads = torch.where(self.osurv[:, 1] == 1)[0].tolist()\n",
    "        self.censored = torch.where(self.osurv[:, 1] == 0)[0].tolist()\n",
    "        if not self.deads:\n",
    "            raise ValueError(\"No uncensored events found\")\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "    def __iter__(self):\n",
    "        indices = self.deads + self.censored\n",
    "        if self.shuffle:\n",
    "            random.shuffle(self.deads)\n",
    "            random.shuffle(self.censored)\n",
    "            indices = self.deads + self.censored\n",
    "            random.shuffle(indices)\n",
    "\n",
    "        ptr = 0\n",
    "        n = len(indices)\n",
    "\n",
    "        while ptr < n:\n",
    "            remaining = n - ptr\n",
    "            current_batch_size = min(self.batch_size, remaining)\n",
    "\n",
    "            remaining_deads = sum(1 for i in indices[ptr:] if i in self.deads)\n",
    "            ratio = remaining_deads / remaining if remaining > 0 else 0\n",
    "\n",
    "            j_d = np.random.binomial(current_batch_size, ratio)\n",
    "            j_d = max(1, j_d)\n",
    "\n",
    "            batch_indices = []\n",
    "            dead_count = 0\n",
    "            censored_count = 0\n",
    "\n",
    "            for idx in indices[ptr:]:\n",
    "                if idx in self.deads and dead_count < j_d:\n",
    "                    batch_indices.append(idx)\n",
    "                    dead_count += 1\n",
    "                elif idx in self.censored and censored_count < (current_batch_size - j_d):\n",
    "                    batch_indices.append(idx)\n",
    "                    censored_count += 1\n",
    "                if len(batch_indices) == current_batch_size:\n",
    "                    break\n",
    "\n",
    "            ptr += len(batch_indices)\n",
    "\n",
    "            batch_data = [\n",
    "                Data(\n",
    "                    osurv=self.osurv[i].unsqueeze(0),\n",
    "                    clin=self.clin[i].unsqueeze(0),\n",
    "                    omics=self.omics[i].unsqueeze(0)\n",
    "                ) for i in batch_indices\n",
    "            ]\n",
    "\n",
    "            if batch_data:  # only yield if the list isn't empty\n",
    "                yield Batch.from_data_list(batch_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = CoxBatchDataset(osurv_train, clin_train, omics_train, batch_size=10, shuffle=True)\n",
    "val_data = CoxBatchDataset(osurv_val, clin_val, omics_val, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Init] Train CI: nan, Loss: nan | Val CI: 0.0000, Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/500 [00:19<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[95], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Training loop\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;66;03m# Training step\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m     tloss, tci \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m     ci_train\u001b[38;5;241m.\u001b[39mappend(tci)\n\u001b[0;32m     28\u001b[0m     loss_train\u001b[38;5;241m.\u001b[39mappend(tloss)\n",
      "Cell \u001b[1;32mIn[85], line 15\u001b[0m, in \u001b[0;36mtrain_block\u001b[1;34m(model, data)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# calculate Cox' partial likelihood and get the autograd output.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m loss \u001b[38;5;241m=\u001b[39m cox_loss_effron(batch\u001b[38;5;241m.\u001b[39mosurv, pred)\n\u001b[1;32m---> 15\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# update the loss_all object\u001b[39;00m\n\u001b[0;32m     17\u001b[0m loss_all \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\egand\\miniconda3\\envs\\jpnote\\lib\\site-packages\\torch\\_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    625\u001b[0m     )\n\u001b[1;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\egand\\miniconda3\\envs\\jpnote\\lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\egand\\miniconda3\\envs\\jpnote\\lib\\site-packages\\torch\\autograd\\graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    824\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    825\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm  # optional, for a nice progress bar\n",
    "\n",
    "# Training parameters\n",
    "epochs = 500\n",
    "\n",
    "# Metrics tracking\n",
    "ci_val = []\n",
    "ci_train = []\n",
    "loss_val = []\n",
    "loss_train = []\n",
    "\n",
    "# Initial evaluation before training\n",
    "vloss, vci = evaluate_model(model, val_data)\n",
    "tloss, tci = evaluate_model(model, train_data)\n",
    "\n",
    "ci_val.append(float(vci))\n",
    "ci_train.append(float(tci))\n",
    "loss_val.append(float(vloss))\n",
    "loss_train.append(float(tloss))\n",
    "\n",
    "print(f\"[Init] Train CI: {tci:.4f}, Loss: {tloss:.4f} | Val CI: {vci:.4f}, Loss: {vloss:.4f}\")\n",
    "\n",
    "# Training loop\n",
    "for epoch in tqdm(range(1, epochs + 1), desc=\"Training\"):\n",
    "    # Training step\n",
    "    tloss, tci = train_block(model, train_data)\n",
    "    ci_train.append(tci)\n",
    "    loss_train.append(tloss)\n",
    "\n",
    "    # Validation step\n",
    "    vloss, vci = evaluate_model(model, val_data)\n",
    "    ci_val.append(vci)\n",
    "    loss_val.append(vloss)\n",
    "\n",
    "    # Print progress\n",
    "    print(f\"Epoch {epoch:03d} | Train CI: {tci:.4f}, Loss: {tloss:.4f} | Val CI: {vci:.4f}, Loss: {vloss:.4f}\")\n",
    "\n",
    "    # Optional: save best model\n",
    "    # if vci == max(ci_val):\n",
    "    #     torch.save(model.state_dict(), \"best_model.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([554, 554])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(len(gene_list), omics_train.shape[1]) \n",
    "print(x.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jpnote",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
